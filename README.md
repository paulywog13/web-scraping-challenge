# web-scraping-challenge

The goal of this challenge was use Jupyter Notebook in order to use splinter and BeautifulSoup scrape data regarding the planet Mars from a variety of websites and then to use Visual Studio Code to create a website to display the scraped data. I used Visual Studio Code py files pull the data from the websites,an app.py file to process the data into a Mongo Database, and then finally a VSCode index.html file to create a website in order to dispay the data.  

Files included in this challenge: mission_to_mars.ipynb, mars_space_images.py, mars_news.py, mars_hemispheres.py, mars_facts.py, app.py

Other files included and index.html inside of the templates folder.

Dependencies used: pandas, splinter, BeautifulSoup, webdriver_manager.chrome, requests, 

My main takeaway from this project is that learning how websites are coded is great for understanding how to scrape for the data needed and BeautifulSoup is a great tool for scraping data from websites. It was exciting learning how to use BeautifulSoup but converting the scaping  code and data to create a new website is quite difficult.

The most difficult parts of the project were creating the app.py code to capture and store the data and then pulling the data to display it correctly from the Database.

Overall, I found this homework challenge to be the quite challenging but a great learning experience as I hadn't had any previous experience with inspecting websites and seeing how they were constructed. I am looking forward to more challenges like this one to continue to challenge my knowledge and understanding.